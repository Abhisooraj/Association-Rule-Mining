{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Rule Mining:\n",
    "## **APRIORI ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All existing API are listed above....\n",
      "TransactionEncoder()\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import collections\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "print(\"All existing API are listed above....\") \n",
    "te = TransactionEncoder()\n",
    "print (te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DATAFRAME:\n",
    "    def read_file(self):\n",
    "        os.chdir(\"C:/users/hp/Python_Anaconda Datasets\")\n",
    "        print(\"current working directory is \"+os.getcwd())\n",
    "        print(\"if this is not your working directory, please set in source code\")\n",
    "        user_input = input(\"Enter your file name it should be a json file:\")\n",
    "        input_path=os.getcwd()+\"\\\\\"+user_input\n",
    "        print(\" \")\n",
    "        df=pd.DataFrame()\n",
    "        fr=open(input_path,\"r\")\n",
    "    def parse_file(self):\n",
    "        jsondata=[]\n",
    "        jsonValue=[]\n",
    "        try:\n",
    "            user_input1 = input(\"Enter your output file name IN .CSV  : \")\n",
    "            output_path=os.getcwd()+\"\\\\\"+user_input1\n",
    "            print(\"output file path is : \"+output_path)\n",
    "        except IOError:\n",
    "            print (\"could not read file\", fr)\n",
    "        except IOError:\n",
    "            print (\"Output file creation error \", fw)\n",
    "        try:\n",
    "            for line in open('RealData.json') :\n",
    "                jsondata.append(json.loads(line))\n",
    "                #print(line)\n",
    "            readJSON=list(jsondata)\n",
    "            for x in jsondata:\n",
    "                x[\"threat type\"]=[\"victim vulnerable service\"]\n",
    "                x.setdefault('cc',\"NK\")\n",
    "                x.setdefault('threat type',\"NK\")\n",
    "                x.setdefault('port',\"0\")\n",
    "                x.setdefault('region',\"NK\") \n",
    "        #       dict.setdefault('ID', \"No ID\")\n",
    "                x.setdefault('city',\"NK\")\n",
    "                x.setdefault('asn',\"0\")\n",
    "                x.setdefault('ip',\"0.0.0.0\")\n",
    "                x.setdefault('as name',\"NK\")\n",
    "                x.setdefault('vulnerability',\"NK\")\n",
    "                x.setdefault('protocol',\"NK\")\n",
    "                str1= x[\"cc\"]+x[\"threat type\"]+x[\"port\"]+x[\"reported asn\"]+x[\"region\"]+x[\"region\"]+x[\"city\"]+x[\"reported cc\"]+x[\"asn\"]+x[\"ip\"]+x[\"as name\"]+x[\"vulnerability\"]+x[\"protocol\"]\n",
    "                #print(str1)\n",
    "                jsonValue.append(str1)\n",
    "            te_ary = te.fit(jsonValue).transform(jsonValue)\n",
    "            print(\"Transaction Encoded Array is showing in your output text file..\")\n",
    "            #print(te_ary)\n",
    "            df = pd.DataFrame(te_ary,columns=te.columns_)  \n",
    "        except IOError:\n",
    "            print (\"Output file creation error \")\n",
    "        print(\"data frame is presenting in your output text file..\")\n",
    "        print(\"\")\n",
    "        print(\"cc:\",\"threat type:\",\"port:\",\"region:\",\"city:\",\"asn:\",\"ip:\",\"as name:\",\"vulnerability:\",\"protocol: In this way \")\n",
    "        df\n",
    "        frequent_itemsets = apriori(df, min_support=0.01, use_colnames=True)\n",
    "        frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "        frequent_itemsets\n",
    "        #print(frequent_itemsets['itemsets'])\n",
    "        #frequent_itemsets[ (frequent_itemsets['length'] == 2) & (frequent_itemsets['support'] >= 0.2) ]\n",
    "        print(\"Your Apriori algorithm implemtnted now check your output file :\")\n",
    "        frequent_itemsets[ (frequent_itemsets['length'] == 2) & (frequent_itemsets['support'] >= 0.6) ]\n",
    "        print(\"Your Apriori algorithm implemtnted now check your output file :\")\n",
    "        association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "        print(\"Your Apriori algorithm implemtnted now check your output file :\")\n",
    "        rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.2)\n",
    "        rules\n",
    "        print(\"Your Apriori algorithm implemtnted now check your output file :\")\n",
    "        fw=open(output_path,\"w+\")\n",
    "        df.to_string(fw)\n",
    "        fw.write('THE FREQUENT ITEMSETS ARE LISTED BELOW')\n",
    "        frequent_itemsets.to_string(fw)\n",
    "        fw.write('THE RULES ARE LISTED BELOW')\n",
    "        rules.to_string(fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current working directory is C:\\users\\hp\\Python_Anaconda Datasets\n",
      "if this is not your working directory, please set in source code\n",
      "Enter your file name it should be a json file:RealData.json\n",
      " \n"
     ]
    }
   ],
   "source": [
    "DF=DATAFRAME()\n",
    "#object of the class....\n",
    "DF.read_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your output file name IN .CSV  : RealData.csv\n",
      "output file path is : C:\\users\\hp\\Python_Anaconda Datasets\\RealData.csv\n",
      "Transaction Encoded Array is showing in your output text file..\n",
      "data frame is presenting in your output text file..\n",
      "\n",
      "cc: threat type: port: region: city: asn: ip: as name: vulnerability: protocol: In this way \n",
      "Your Apriori algorithm implemtnted now check your output file :\n",
      "Your Apriori algorithm implemtnted now check your output file :\n",
      "Your Apriori algorithm implemtnted now check your output file :\n",
      "Your Apriori algorithm implemtnted now check your output file :\n"
     ]
    }
   ],
   "source": [
    "DF.parse_file()\n",
    "print(\"\\n\\t the Rules are added in your output file.....\\n now again check your output file.. \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
